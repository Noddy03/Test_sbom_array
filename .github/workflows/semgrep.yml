name: Top Repos SBOM Security Scan

on:
  workflow_dispatch:
    inputs:
      language:
        description: "Programming language for ranking repos"
        required: true
        default: "Java"
      top_n:
        description: "How many top repos to consider"
        required: false
        default: "20"

permissions:
  contents: read
  security-events: write

jobs:
  discover_repos:
    runs-on: ubuntu-latest
    outputs:
      repo_list: ${{ steps.collect.outputs.repo_list }}

    steps:
      - name: Install Python dependencies
        run: |
          pip install requests

      - name: Fetch and filter repositories (recursive SBOM detection)
        id: collect
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          INPUT_LANGUAGE: ${{ inputs.language }}
          INPUT_TOP_N: ${{ inputs.top_n }}
        run: |
          python << 'EOF'
          import os, requests, urllib.parse, time

          lang = os.environ["INPUT_LANGUAGE"]
          top_n = int(os.environ["INPUT_TOP_N"])
          token = os.environ["GITHUB_TOKEN"]
          headers = {"Authorization": f"token {token}"}

          # 1️⃣ Fetch top N repos by language
          q = urllib.parse.quote(f"language:{lang}")
          url = f"https://api.github.com/search/repositories?q={q}&sort=stars&order=desc&per_page={top_n}"
          print("DEBUG: Search URL:", url)

          r = requests.get(url, headers=headers)
          r.raise_for_status()
          repos = [i["full_name"] for i in r.json()["items"]]
          print("DEBUG: Initial repos:", repos)

          # SBOM filename patterns (expanded)
          sbom_keywords = [
              "sbom", "bom",
              "cyclonedx", "spdx",
              "sbom.json", "sbom.xml",
              "bom.json", "bom.xml",
              "package-lock.cdx.json",
          ]

          matches = []

          # 2️⃣ Recursive SBOM search using Git Trees API
          for repo in repos:
            print(f"Checking SBOM in {repo} ...")
            tree_url = f"https://api.github.com/repos/{repo}/git/trees/HEAD?recursive=1"

            t = requests.get(tree_url, headers=headers)
            if t.status_code == 403:   # rate limit
              print("Hit rate limit. Sleeping...")
              time.sleep(30)
              t = requests.get(tree_url, headers=headers)

            if not t.ok:
              print("FAILED:", repo, t.text)
              continue

            files = [
              node["path"].lower()
              for node in t.json().get("tree", [])
              if node.get("type") == "blob"
            ]

            if any(keyword in f for keyword in sbom_keywords for f in files):
              print("✔ SBOM FOUND:", repo)
              matches.append(repo)
            else:
              print("✖ No SBOM in:", repo)

          print("FINAL SBOM repos:", matches)
          print(f"::set-output name=repo_list::{','.join(matches)}")
          EOF

  scan_repos:
    needs: discover_repos

    if: ${{ needs.discover_repos.outputs.repo_list != '' }}

    strategy:
      fail-fast: false
      matrix:
        repo: ${{ fromJson('["' + join(needs.discover_repos.outputs.repo_list, '","') + '"]') }}

    runs-on: ubuntu-latest

    steps:
      - name: Install tools
        run: |
          sudo apt-get update
          sudo apt-get install -y jq
          pip install semgrep requests

      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          repository: ${{ matrix.repo }}
          path: project-src

      - name: Install dependencies (auto-detect)
        working-directory: project-src
        run: |
          if [ -f pom.xml ]; then
            mvn -B dependency:go-offline
          elif [ -f package.json ]; then
            npm ci || npm install
          elif [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi

      - name: Run Snyk SCA
        working-directory: project-src
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        run: |
          snyk test --all-projects --json > ../snyk-sca.json || echo '{"vulnerabilities":[]}' > ../snyk-sca.json

      - name: Run Snyk SAST
        working-directory: project-src
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        run: |
          snyk code test --sarif-file ../snyk-code.sarif || echo '{"runs":[]}' > ../snyk-code.sarif

      - name: Run Semgrep
        working-directory: project-src
        run: |
          semgrep scan --config p/security-audit --sarif-file ../semgrep.sarif . || echo '{"runs":[]}' > ../semgrep.sarif

      - name: Compute summary for repo
        id: compute
        run: |
          REPO="${{ matrix.repo }}"

          SCA_LOW=$(jq '[.vulnerabilities[] | select(.severity=="low")] | length' snyk-sca.json)
          SCA_MEDIUM=$(jq '[.vulnerabilities[] | select(.severity=="medium")] | length' snyk-sca.json)
          SCA_HIGH=$(jq '[.vulnerabilities[] | select(.severity=="high")] | length' snyk-sca.json)
          SCA_CRITICAL=$(jq '[.vulnerabilities[] | select(.severity=="critical")] | length' snyk-sca.json)

          SAST_LOW=$(jq '[.runs[].results[] | select(.level=="note")] | length' snyk-code.sarif)
          SAST_MEDIUM=$(jq '[.runs[].results[] | select(.level=="warning")] | length' snyk-code.sarif)
          SAST_HIGH=$(jq '[.runs[].results[] | select(.level=="error")] | length' snyk-code.sarif)
          SAST_CRITICAL=$(jq '[.runs[].results[] | select(.ruleId | test("critical"))] | length' snyk-code.sarif)

          SEM_LOW=$(jq '[.runs[].results[] | select(.level=="INFO")] | length' semgrep.sarif)
          SEM_MEDIUM=$(jq '[.runs[].results[] | select(.level=="WARNING")] | length' semgrep.sarif)
          SEM_HIGH=$(jq '[.runs[].results[] | select(.level=="ERROR")] | length' semgrep.sarif)
          SEM_CRITICAL=$(jq '[.runs[].results[] | select(.ruleId | test("critical"))] | length' semgrep.sarif)

          TOTAL=$((SCA_LOW+SCA_MEDIUM+SCA_HIGH+SCA_CRITICAL+SAST_LOW+SAST_MEDIUM+SAST_HIGH+SAST_CRITICAL+SEM_LOW+SEM_MEDIUM+SEM_HIGH+SEM_CRITICAL))

          echo "repo,SCA_LOW,SCA_MEDIUM,SCA_HIGH,SCA_CRITICAL,SAST_LOW,SAST_MEDIUM,SAST_HIGH,SAST_CRITICAL,SEM_LOW,SEM_MEDIUM,SEM_HIGH,SEM_CRITICAL,TOTAL" > summary_${REPO//\//_}.csv
          echo "$REPO,$SCA_LOW,$SCA_MEDIUM,$SCA_HIGH,$SCA_CRITICAL,$SAST_LOW,$SAST_MEDIUM,$SAST_HIGH,$SAST_CRITICAL,$SEM_LOW,$SEM_MEDIUM,$SEM_HIGH,$SEM_CRITICAL,$TOTAL" >> summary_${REPO//\//_}.csv

      - name: Upload Repo CSV
        uses: actions/upload-artifact@v4
        with:
          name: "repo-summary-${{ matrix.repo }}"
          path: summary_${{ matrix.repo//\//_ }}.csv


  merge_results:
    needs: scan_repos
    runs-on: ubuntu-latest

    steps:
      - name: Download all CSVs
        uses: actions/download-artifact@v4
        with:
          path: results

      - name: Merge CSVs
        run: |
          echo "repo,SCA_LOW,SCA_MEDIUM,SCA_HIGH,SCA_CRITICAL,SAST_LOW,SAST_MEDIUM,SAST_HIGH,SAST_CRITICAL,SEM_LOW,SEM_MEDIUM,SEM_HIGH,SEM_CRITICAL,TOTAL" > summary.csv
          cat results/**/*.csv | grep -v "repo,SCA_LOW" >> summary.csv

      - name: Upload Summary CSV
        uses: actions/upload-artifact@v4
        with:
          name: final-summary
          path: summary.csv
