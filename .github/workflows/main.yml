name: Fetch Top IoT Repositories + Trivy/Conan SBOM Scan (NTIA + BSI V2)

on:
  workflow_dispatch:
    inputs:
      language:
        description: "Programming language to scan (C++, Python, Java, etc.)"
        required: true
        default: "C++"

permissions:
  contents: read
  security-events: write
  actions: read

jobs:
  # ================================================================
  # 1. FETCH TOP REPOS
  # ================================================================
  fetch_top_repos:
    runs-on: ubuntu-latest
    outputs:
      repo_list: ${{ steps.fetch.outputs.repo_list }}

    steps:
      - name: Install jq
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq

      - name: Fetch repositories
        id: fetch
        env:
          LANG: ${{ github.event.inputs.language }}
          GH_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail

          RAW_Q="topic:IoT language:$LANG fork:false archived:false"
          echo "Query: $RAW_Q"

          REPOS=$(gh api -X GET /search/repositories \
             --raw-field q="$RAW_Q" \
             --raw-field sort=stars \
             --raw-field order=desc \
             --raw-field per_page=50 \
             --jq '.items[].full_name'
          )

          echo "Found repos:"
          echo "$REPOS"

          JSON_ARRAY=$(printf "%s\n" "$REPOS" | jq -R -s -c 'split("\n")[:-1]')
          echo "repo_list=$JSON_ARRAY" >> $GITHUB_OUTPUT

  # ================================================================
  # 2. SBOM SCAN
  # ================================================================
  sbom_scan:
    needs: fetch_top_repos
    runs-on: ubuntu-latest
    continue-on-error: true

    strategy:
      fail-fast: false
      matrix:
        repo: ${{ fromJSON(needs.fetch_top_repos.outputs.repo_list) }}

    steps:
      - name: Install Conan + jq + Trivy
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq wget curl
          pipx install conan
          curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh \
            | sudo sh -s -- -b /usr/local/bin

      - name: Checkout repository
        env:
          REPO: ${{ matrix.repo }}
          TOKEN: ${{ secrets.MY_PERSONAL_TOKEN || github.token }}
        run: |
          if git clone --depth=1 "https://$TOKEN@github.com/$REPO" project-src; then
              echo "skip_repo=false" >> $GITHUB_ENV
          else
              echo "skip_repo=true" >> $GITHUB_ENV
          fi

      - name: Fetch GitHub license metadata
        if: env.skip_repo != 'true'
        env:
          REPO: ${{ matrix.repo }}
          GH_TOKEN: ${{ github.token }}
        run: |
          gh api "/repos/$REPO/license" > project-src/gh-license.json \
            || echo '{"license":{"id":"NOASSERTION"}}' > project-src/gh-license.json

      - name: Conan SBOM
        if: env.skip_repo != 'true'
        run: |
          cd project-src
          conan profile detect --force || true
          conan graph info . --format=json > conan-sbom.json \
            || echo '{"components":[]}' > conan-sbom.json

      - name: Trivy SBOM
        if: env.skip_repo != 'true'
        run: |
          trivy fs --scanners vuln,license --format cyclonedx \
            -o project-src/trivy-fs.json project-src \
            || echo '{"components":[]}' > project-src/trivy-fs.json

      - name: NTIA Compliance
        if: env.skip_repo != 'true'
        run: |
          docker run --rm -v $PWD/project-src:/sbom ghcr.io/interlynk-io/sbomqs:latest \
            compliance --ntia /sbom/trivy-fs.json \
            > project-src/compliance_NTIA.json || true

      - name: BSI v2 Compliance
        if: env.skip_repo != 'true'
        run: |
          docker run --rm -v $PWD/project-src:/sbom ghcr.io/interlynk-io/sbomqs:latest \
            compliance --bsi-v2 /sbom/trivy-fs.json \
            > project-src/compliance_BSI.json || true

      - name: Score SBOM
        if: env.skip_repo != 'true'
        run: |
          docker run --rm -v $PWD/project-src:/sbom ghcr.io/interlynk-io/sbomqs:latest \
            score /sbom/trivy-fs.json --json \
            > project-src/score.json || true

      - name: Sanitize name
        run: |
          SAFE="${{ matrix.repo }}"
          SAFE="${SAFE//\//_}"
          echo "SAFE_NAME=$SAFE" >> $GITHUB_ENV

      - name: Upload SBOM artifacts
        uses: actions/upload-artifact@v4
        with:
          name: sbom-${{ env.SAFE_NAME }}
          path: project-src/*.json

  # ================================================================
  # 3. AGGREGATION – TSV SUMMARY (SAFE JSON HANDLING)
  # ================================================================
  aggregate_results:
    name: Aggregate SBOMQS Results
    needs: sbom_scan
    runs-on: ubuntu-latest
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: results/
      - name: Install Python + Pandas
        run: |
          sudo apt-get update && sudo apt-get install -y python3-pip
          pip install pandas
      - name: Aggregate all JSON results
        run: |
          python3 <<'EOF'
          import json, glob, pandas as pd, os
          def load_json_safe(path):
              try:
                  with open(path) as f:
                      content = f.read().strip()
                      if not content: return None
                      return json.loads(content)
              except Exception as e:
                  print(f"⚠️ Skipping invalid JSON in {path}: {e}")
                  return None
          records = []
          for path in glob.glob("results/**/score_evaluation.json", recursive=True):
              repo = os.path.basename(os.path.dirname(path))
              data = load_json_safe(path)
              if data: data["repository"] = repo; records.append(data)
          for std in ["BSI","NTIA"]:
              for path in glob.glob(f"results/**/compliance_{std}.json", recursive=True):
                  repo = os.path.basename(os.path.dirname(path))
                  data = load_json_safe(path)
                  if data:
                      data["repository"] = repo
                      data["standard"] = std
                      records.append(data)
          if not records:
              print("❌ No valid SBOMQS data found.")
          else:
              df = pd.json_normalize(records)
              df.to_csv("sbomqs_summary.csv", index=False)
              print(f"✅ Aggregated {len(records)} SBOMQS results successfully.")
          EOF
      - name: Upload aggregated summary
        uses: actions/upload-artifact@v4
        with:
          name: sbomqs-summary
          path: sbomqs_summary.csv
