name: Fetch Top IoT Repositories + Trivy/Conan/Syft SBOM Merge + Trivy Vulnerabilities (NTIA + BSI V2 Bulletproof)

on:
  workflow_dispatch:
    inputs:
      language:
        description: "Programming language to scan (C++, Python, Java, etc.)"
        required: true
        default: "C++"

permissions:
  contents: read
  security-events: write
  actions: read

jobs:

  fetch_top_repos:
    runs-on: ubuntu-latest
    outputs:
      repo_list: ${{ steps.fetch.outputs.repo_list }}

    steps:
      - name: Install jq
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq

      - name: Fetch repositories
        id: fetch
        env:
          LANG: ${{ github.event.inputs.language }}
          GH_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail
          RAW_Q="topic:IoT language:$LANG fork:false archived:false"
          REPOS=$(gh api -X GET /search/repositories \
              --raw-field q="$RAW_Q" \
              --raw-field sort=stars \
              --raw-field order=desc \
              --raw-field per_page=100 \
              --jq '.items[].full_name')
          JSON_ARRAY=$(printf "%s\n" "$REPOS" | jq -R -s -c 'split("\n")[:-1]')
          echo "repo_list=$JSON_ARRAY" >> $GITHUB_OUTPUT

  sbom_scan:
    needs: fetch_top_repos
    runs-on: ubuntu-latest
    continue-on-error: true

    strategy:
      fail-fast: false
      matrix:
        repo: ${{ fromJSON(needs.fetch_top_repos.outputs.repo_list) }}

    steps:

      - name: Install Conan + CycloneDX + jq + Trivy + other tools
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq wget curl python3-pip rpm gnupg lsb-release
          pip install --upgrade pip
          pip install conan cyclonedx-bom

          # Trivy installation
          curl -fsSL https://aquasecurity.github.io/trivy-repo/deb/public.key \
            | sudo gpg --dearmor -o /usr/share/keyrings/trivy.gpg
          echo "deb [signed-by=/usr/share/keyrings/trivy.gpg] https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -cs) main" \
            | sudo tee /etc/apt/sources.list.d/trivy.list
          sudo apt-get update -y
          sudo apt-get install -y trivy

      - name: Install Syft (Anchore) to /usr/bin (chosen)
        run: |
          # install Syft into /usr/bin so the runner can execute it reliably
          curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b /usr/bin
          /usr/bin/syft version || /usr/bin/syft -v

      - name: Checkout repository
        env:
          REPO: ${{ matrix.repo }}
          TOKEN: ${{ secrets.MY_PERSONAL_TOKEN || github.token }}
        run: |
          if git clone --depth=1 "https://$TOKEN@github.com/$REPO" project-src; then
              echo "skip_repo=false" >> $GITHUB_ENV
          else
              echo "skip_repo=true" >> $GITHUB_ENV
          fi

      - name: (optional) Copy uploaded reference file into workspace
        if: env.skip_repo != 'true'
        run: |
          mkdir -p project-src/.scan_refs || true
          # developer-uploaded file (will be converted to URL by external tooling)
          if [ -f "/mnt/data/TOP 50 IOT REPOSITRIES.txt" ]; then
            cp "/mnt/data/TOP 50 IOT REPOSITRIES.txt" project-src/.scan_refs/ || true
            echo "copied_uploaded_refs=/mnt/data/TOP 50 IOT REPOSITRIES.txt" >> $GITHUB_OUTPUT
          fi

      - name: Fetch GitHub license metadata
        if: env.skip_repo != 'true'
        env:
          REPO: ${{ matrix.repo }}
          GH_TOKEN: ${{ github.token }}
        run: |
          gh api -H "Accept: application/vnd.github+json" "/repos/$REPO/license" \
              > project-src/gh-license.json 2>/dev/null \
              || echo '{"license":{"spdx_id":"NOASSERTION"}}' > project-src/gh-license.json

      - name: Local SPDX license fallback
        if: env.skip_repo != 'true'
        run: |
          FILE=$(find project-src -maxdepth=4 -type f \
             -iregex ".*\(LICENSE\|LICENCE\|COPYING\|COPYRIGHT\|LICENSE\.md\|LICENSE\.txt\)" | head -1)
          if [ -n "$FILE" ]; then
               cp "$FILE" project-src/local-license.txt
          else
               echo "" > project-src/local-license.txt
          fi

      - name: Conan SBOM
        if: env.skip_repo != 'true'
        run: |
          cd project-src
          conan profile detect --force || true
          conan graph info . --format=json > conan-sbom.json \
              || echo '{"components":[]}' > conan-sbom.json

      - name: Trivy SBOM (primary vulnerability & license evidence)
        if: env.skip_repo != 'true'
        run: |
          trivy fs --scanners vuln,license --format cyclonedx \
              -o project-src/trivy-fs.json project-src \
              || echo '{"components":[]}' > project-src/trivy-fs.json

      - name: Syft SBOM (metadata enrichment)
        if: env.skip_repo != 'true'
        run: |
          /usr/bin/syft dir:project-src -o cyclonedx-json > project-src/syft-sbom.json || \
            echo '{"components":[]}' > project-src/syft-sbom.json

      - name: Normalize SBOM component arrays
        if: env.skip_repo != 'true'
        run: |
          for f in project-src/trivy-fs.json project-src/syft-sbom.json; do
            if [ -f "$f" ]; then
              # ensure components array exists and is an array
              jq 'if has("components") then . else (. + {components: []}) end | .components |= (if type=="array" then . else [] end)' "$f" > tmp && mv tmp "$f" || true
            fi
          done

      - name: Merge Syft metadata into Trivy SBOM (Python — Trivy primary, Syft enriches)
        if: env.skip_repo != 'true'
        run: |
          # Python merge: reliable, robust merging (Trivy is authoritative; Syft enriches missing fields)
          python3 <<'PY'
          import json, os
          TRIVY = "project-src/trivy-fs.json"
          SYFT  = "project-src/syft-sbom.json"
          OUT   = "project-src/merged-sbom.json"

          def load(path):
              if not os.path.exists(path):
                  return {"components": []}
              try:
                  with open(path) as f:
                      return json.load(f)
              except Exception:
                  return {"components": []}

          trivy = load(TRIVY)
          syft  = load(SYFT)

          tcom = trivy.get("components", []) or []
          scom = syft.get("components", []) or []

          # build indices for syft by purl and name:version
          idx_purl = {}
          idx_nv   = {}
          for c in scom:
              purl = c.get("purl")
              name = c.get("name")
              ver  = c.get("version")
              if purl:
                  idx_purl[purl] = c
              if name and ver:
                  idx_nv[f"{name}:{ver}"] = c

          def enrich(base, extra):
              fields = ["supplier", "purl", "hashes", "externalReferences",
                        "evidence", "copyright", "type", "properties"]
              for k in fields:
                  if not base.get(k) and extra.get(k):
                      base[k] = extra[k]
              return base

          merged = []
          # enrich Trivy components
          for c in tcom:
              new = dict(c)
              purl = c.get("purl")
              name = c.get("name")
              ver  = c.get("version")
              matched = None
              if purl and purl in idx_purl:
                  matched = idx_purl[purl]
              elif name and ver and f"{name}:{ver}" in idx_nv:
                  matched = idx_nv[f"{name}:{ver}"]
              if matched:
                  new = enrich(new, matched)
              merged.append(new)

          # append syft components not already present (by purl or name:version)
          existing_purls = {m.get("purl") for m in merged if m.get("purl")}
          existing_nv = { (m.get("name"), m.get("version")) for m in merged }
          for c in scom:
              purl = c.get("purl")
              name = c.get("name")
              ver  = c.get("version")
              if purl and purl in existing_purls:
                  continue
              if name and ver and (name, ver) in existing_nv:
                  continue
              merged.append(c)

          # If nothing in merged, fall back to trivy
          if len(merged) == 0:
              merged = tcom

          outobj = {"components": merged}
          with open(OUT, "w") as f:
              json.dump(outobj, f, indent=2)
          PY

          # safety: ensure merged-sbom exists
          if [ ! -s project-src/merged-sbom.json ]; then
            echo "merged missing — fallback to trivy"
            cp project-src/trivy-fs.json project-src/merged-sbom.json || true
          fi

      - name: Determine final assigned license
        if: env.skip_repo != 'true'
        run: |
          GH_LICENSE=$(jq -r '.license.spdx_id // empty' project-src/gh-license.json)
          FILE_LICENSE=$(grep -Eo "SPDX-License-Identifier:[ ]*[A-Za-z0-9.\-+]+" \
                         project-src/local-license.txt 2>/dev/null | head -1 | awk -F': ' '{print $2}')
          FINAL="${GH_LICENSE:-$FILE_LICENSE}"
          [ -z "$FINAL" ] && FINAL="NOASSERTION"
          echo "$FINAL" > project-src/final_license.txt
          echo "final_license=$FINAL" >> $GITHUB_OUTPUT

      - name: Apply final license to MERGED SBOM components (only fill missing licenses)
        if: env.skip_repo != 'true'
        run: |
          SBOM="project-src/merged-sbom.json"
          FINAL=$(cat project-src/final_license.txt)
          jq --arg lic "$FINAL" '
            .components |= map(
              if (.licenses? | length // 0) == 0 then
                . + { licenses: [{ "license": { "id": $lic }}] }
              else
                .licenses = ( .licenses | map(
                  if (.license? and (.license.id? // "") == "") then
                    .license.id = $lic | .
                  else .
                  end
                )) | .
              end
            )
          ' "$SBOM" > tmp && mv tmp "$SBOM"

      - name: (optional) Ensure SBOM-level dataLicense and metadata.author/supplier exist
        if: env.skip_repo != 'true'
        run: |
          SBOM="project-src/merged-sbom.json"
          FINAL=$(cat project-src/final_license.txt)
          jq --arg lic "$FINAL" '
            .dataLicense = (.dataLicense // $lic) |
            .metadata = (.metadata // {}) |
            .metadata.authors = (.metadata.authors // [{"name":"automated-scan"}]) |
            .metadata.component = (.metadata.component // {"type":"application","name": ( .metadata.component.name // "unknown" )})
          ' "$SBOM" > tmp && mv tmp "$SBOM"

      - name: NTIA Compliance (use merged SBOM)
        if: env.skip_repo != 'true'
        run: |
          docker run --rm -v $PWD/project-src:/sbom ghcr.io/interlynk-io/sbomqs:latest \
             compliance --ntia /sbom/merged-sbom.json \
             > project-src/compliance_NTIA.json || true

      - name: BSI v2 Compliance (use merged SBOM)
        if: env.skip_repo != 'true'
        run: |
          docker run --rm -v $PWD/project-src:/sbom ghcr.io/interlynk-io/sbomqs:latest \
             compliance --bsi-v2 /sbom/merged-sbom.json \
             > project-src/compliance_BSI.json || true

      - name: Score SBOM (use merged SBOM)
        if: env.skip_repo != 'true'
        run: |
          docker run --rm -v $PWD/project-src:/sbom ghcr.io/interlynk-io/sbomqs:latest \
             score /sbom/merged-sbom.json --json \
             > project-src/score.json || true

      - name: Sanitize artifact name
        id: sanitize
        run: |
          SAFE="${{ matrix.repo }}"
          SAFE="${SAFE//\//_}"
          echo "name=$SAFE" >> $GITHUB_OUTPUT

      - name: Upload SBOM reports
        uses: actions/upload-artifact@v4
        with:
          name: sbom-reports-${{ steps.sanitize.outputs.name }}
          path: project-src/*
          if-no-files-found: warn

  aggregate_results:
    name: Aggregate SBOMQS Results
    needs: sbom_scan
    runs-on: ubuntu-latest

    steps:
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: results/

      - name: Install Python + Pandas
        run: |
          sudo apt-get update
          sudo apt-get install -y python3-pip
          pip install pandas

      - name: Aggregate SBOMQS results to CSV
        run: |
          python3 <<'PY'
          import json, glob, pandas as pd, os, re

          def load_json(path):
              try:
                  with open(path) as f:
                      txt = f.read().strip()
                      return json.loads(txt) if txt else None
              except:
                  return None

          def load_text(path):
              try:
                  with open(path) as f:
                      return f.read().strip()
              except:
                  return ""

          rows = []

          for folder in glob.glob("results/*/"):
              repo = os.path.basename(os.path.dirname(folder))

              trivy = load_json(os.path.join(folder, "trivy-fs.json")) or {}
              syft = load_json(os.path.join(folder, "syft-sbom.json")) or {}
              merged = load_json(os.path.join(folder, "merged-sbom.json")) or {}
              conan = load_json(os.path.join(folder, "conan-sbom.json")) or {}
              score = load_json(os.path.join(folder, "score.json"))
              ntia  = load_json(os.path.join(folder, "compliance_NTIA.json"))
              bsi   = load_json(os.path.join(folder, "compliance_BSI.json"))

              gh_license = load_json(os.path.join(folder, "gh-license.json")) or {}
              github_license_spdx = gh_license.get("license", {}).get("spdx_id", "")
              github_license_name = gh_license.get("license", {}).get("name", "")

              local_license_txt = load_text(os.path.join(folder, "local-license.txt"))
              m = re.search(r"SPDX-License-Identifier:\s*([A-Za-z0-9.\-+]+)", local_license_txt)
              local_spdx = m.group(1) if m else ""

              final_license = load_text(os.path.join(folder, "final_license.txt"))

              components = merged.get("components", []) or []
              component_names = [c.get("name") for c in components]
              component_versions = [c.get("version") for c in components]
              component_purls = [c.get("purl") for c in components]
              component_suppliers = [c.get("supplier", {}).get("name") if isinstance(c.get("supplier"), dict) else c.get("supplier") for c in components]

              base = {
                  "repository": repo,
                  "github_license_spdx": github_license_spdx,
                  "github_license_name": github_license_name,
                  "local_spdx_license": local_spdx,
                  "final_assigned_license": final_license,
                  "num_trivy_components": len(trivy.get("components", []) or []),
                  "num_syft_components": len(syft.get("components", []) or []),
                  "num_merged_components": len(components),
                  "num_conan_components": len(conan.get("components", [])),
                  "component_names": component_names,
                  "component_versions": component_versions,
                  "component_purls": component_purls,
                  "component_suppliers": component_suppliers,
                  "trivy_scan_success": trivy != {},
                  "syft_scan_success": syft != {},
                  "conan_scan_success": conan != {},
                  "sbom_empty": len(components) == 0,
              }

              if score:
                  rows.append({**base, "type": "score", **score})
              if ntia:
                  rows.append({**base, "type": "ntia", **ntia})
              if bsi:
                  rows.append({**base, "type": "bsi", **bsi})

          df = pd.json_normalize(rows)
          df.to_csv("sbomqs_summary.csv", index=False)
          PY

      - name: Upload summary
        uses: actions/upload-artifact@v4
        with:
          name: sbomqs-summary
          path: sbomqs_summary.csv
          if-no-files-found: ignore
