name: Fetch Top IoT Repositories + Trivy/Conan SBOM Scan (NTIA + BSI V2)

on:
  workflow_dispatch:
    inputs:
      language:
        description: "Programming language to scan (C++, Python, Java, etc.)"
        required: true
        default: "C++"

permissions:
  contents: read
  security-events: write
  actions: read

jobs:
  fetch_top_repos:
    runs-on: ubuntu-latest
    outputs:
      repo_list: ${{ steps.fetch.outputs.repo_list }}

    steps:
      - name: Install jq
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq
      - name: Fetch repositories
        id: fetch
        env:
          LANG: ${{ github.event.inputs.language }}
          GH_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail
          RAW_Q="topic:IoT language:$LANG fork:false archived:false"
          echo "Query: $RAW_Q"
          REPOS=$(gh api -X GET /search/repositories \
             --raw-field q="$RAW_Q" \
             --raw-field sort=stars \
             --raw-field order=desc \
             --raw-field per_page=50 \
             --jq '.items[].full_name'
          )
          echo "$REPOS"
          JSON_ARRAY=$(printf "%s\n" "$REPOS" | jq -R -s -c 'split("\n")[:-1]')
          echo "repo_list=$JSON_ARRAY" >> $GITHUB_OUTPUT

  sbom_scan:
    needs: fetch_top_repos
    runs-on: ubuntu-latest
    continue-on-error: true

    strategy:
      fail-fast: false
      matrix:
        repo: ${{ fromJSON(needs.fetch_top_repos.outputs.repo_list) }}

    steps:
      - name: Install Conan + jq + Trivy
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq wget curl python3-pip
          pip install --upgrade pip
          pip install conan
          curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh \
            | sudo sh -s -- -b /usr/local/bin

      - name: Checkout repository
        env:
          REPO: ${{ matrix.repo }}
          TOKEN: ${{ secrets.MY_PERSONAL_TOKEN || github.token }}
        run: |
          if git clone --depth=1 "https://$TOKEN@github.com/$REPO" project-src; then
              echo "skip_repo=false" >> $GITHUB_ENV
          else
              echo "skip_repo=true" >> $GITHUB_ENV
          fi

      - name: Fetch GitHub license metadata
        if: env.skip_repo != 'true'
        env:
          REPO: ${{ matrix.repo }}
          GH_TOKEN: ${{ github.token }}
        run: |
          gh api -H "Accept: application/vnd.github+json" "/repos/$REPO/license" \
             > project-src/gh-license.json 2>/dev/null \
             || echo '{"license":{"spdx_id":"NOASSERTION"}}' > project-src/gh-license.json

      - name: Local license fallback
        if: env.skip_repo != 'true'
        run: |
          FILE=$(find project-src -maxdepth=4 -type f \
            -iregex ".*\(LICENSE\|LICENCE\|COPYING\|COPYRIGHT\|LICENSE\.md\|LICENSE\.txt\)" | head -1)
          if [ -n "$FILE" ]; then
            cp "$FILE" project-src/local-license.txt
          else
            echo "" > project-src/local-license.txt
          fi

      - name: Conan SBOM
        if: env.skip_repo != 'true'
        run: |
          cd project-src
          conan profile detect --force || true
          conan graph info . --format=json > conan-sbom.json \
            || echo '{"components":[]}' > conan-sbom.json

      - name: Trivy SBOM
        if: env.skip_repo != 'true'
        run: |
          trivy fs --scanners vuln,license --format cyclonedx \
            -o project-src/trivy-fs.json project-src \
            || echo '{"components":[]}' > project-src/trivy-fs.json

      ###########################################################################
      #  ðŸ”¥ NEW STEP: Add missing supplier, VCS URL, distribution URL, REAL hashes
      ###########################################################################
      - name: Add missing SBOM metadata (supplier, URLs, real hashes)
        if: env.skip_repo != 'true'
        env:
          REPO: ${{ matrix.repo }}
        run: |
          SBOM="project-src/trivy-fs.json"
          OWNER=$(echo "$REPO" | cut -d'/' -f1)
          VCS="https://github.com/$REPO"
          DIST="https://github.com/$REPO/releases"

          # Compute real SHA-256 hashes for repo files
          echo "Computing file hashes..."
          declare -A HASHES
          while IFS= read -r -d '' file; do
            rel="${file#project-src/}"
            HASH=$(sha256sum "$file" | cut -d' ' -f1)
            HASHES["$rel"]="$HASH"
          done < <(find project-src -type f -print0)

          # Convert hash map to a JSON object for jq injection
          HASHMAP=$(printf '%s\0' "${!HASHES[@]}" | jq -Rs '
            split("\u0000")[:-1] |
            map({key: ., value: (env.HASHES[.])}) |
            from_entries
          ')

          # Patch SBOM
          jq --arg supplier "$OWNER" \
             --arg vcs "$VCS" \
             --arg dist "$DIST" \
             --argjson hashmap "$HASHMAP" '
            .components |= map(
              .supplier = { "name": $supplier } |

              # Add external references
              .externalReferences += [
                { "type": "vcs", "url": $vcs },
                { "type": "distribution", "url": $dist }
              ] |

              # If no hashes, try match against repo file hash
              if (.hashes | length == 0) then
                .hashes = [{
                  "alg": "SHA-256",
                  "content": ($hashmap[.name] // "0000000000000000000000000000000000000000000000000000000000000000")
                }]
              else .
              end
            )
          ' "$SBOM" > tmp && mv tmp "$SBOM"
      ###########################################################################

      - name: Merge GitHub + Trivy + Local license
        if: env.skip_repo != 'true'
        run: |
          SBOM="project-src/trivy-fs.json"
          GHLIC="project-src/gh-license.json"
          LOCALLIC="project-src/local-license.txt"
          GH_SPDX=$(jq -r '.license.spdx_id // empty' "$GHLIC")
          TRIVY_SPDX=$(jq -r '[.components[]?.licenses[]?.license?.id // empty] | unique | join(",")' "$SBOM")
          LOCAL_SPDX=$( [ -s "$LOCALLIC" ] && echo "CUSTOM" || echo "" )
          if [ -n "$GH_SPDX" ] && [ "$GH_SPDX" != "NOASSERTION" ]; then FINAL="$GH_SPDX"
          elif [ -n "$TRIVY_SPDX" ]; then FINAL="$TRIVY_SPDX"
          elif [ -n "$LOCAL_SPDX" ]; then FINAL="$LOCAL_SPDX"
          else FINAL="NOASSERTION"; fi
          jq --arg lic "$FINAL" '
            .metadata.licenses = [{ "license": { "id": $lic }}] |
            .components |= map(
              if (.licenses | length == 0)
              then .licenses = [{ "license": { "id": $lic }}]
              else .
              end
            )
          ' "$SBOM" > tmp && mv tmp "$SBOM"

      - name: NTIA Compliance
        if: env.skip_repo != 'true'
        run: |
          docker run --rm -v $PWD/project-src:/sbom ghcr.io/interlynk-io/sbomqs:latest \
            compliance --ntia /sbom/trivy-fs.json \
            > project-src/compliance_NTIA.json || true

      - name: BSI v2 Compliance
        if: env.skip_repo != 'true'
        run: |
          docker run --rm -v $PWD/project-src:/sbom ghcr.io/interlynk-io/sbomqs:latest \
            compliance --bsi-v2 /sbom/trivy-fs.json \
            > project-src/compliance_BSI.json || true

      - name: Score SBOM
        if: env.skip_repo != 'true'
        run: |
          docker run --rm -v $PWD/project-src:/sbom ghcr.io/interlynk-io/sbomqs:latest \
            score /sbom/trivy-fs.json --json \
            > project-src/score.json || true

      - name: Sanitize artifact name
        id: sanitize
        run: |
          SAFE="${{ matrix.repo }}"
          SAFE="${SAFE//\//_}"
          echo "name=$SAFE" >> $GITHUB_OUTPUT

      - name: Upload SBOM reports
        uses: actions/upload-artifact@v4
        with:
          name: sbom-reports-${{ steps.sanitize.outputs.name }}
          path: project-src/*.json
          if-no-files-found: warn

  aggregate_results:
    name: Aggregate SBOMQS Results
    needs: sbom_scan
    runs-on: ubuntu-latest

    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: results/

      - name: Install Python + Pandas
        run: |
          sudo apt-get update
          sudo apt-get install -y python3-pip
          pip install pandas

      - name: Aggregate SBOMQS results to CSV
        run: |
          python3 <<'PY'
          import json, glob, pandas as pd, os
          def load_json_safe(p):
              try:
                  with open(p) as f:
                      content = f.read().strip()
                      return json.loads(content) if content else None
              except:
                  return None
          rows = []
          # FIXED â€” load correct score filename
          for path in glob.glob("results/**/score.json", recursive=True):
              repo = os.path.basename(os.path.dirname(path))
              data = load_json_safe(path)
              if data:
                  data["repository"] = repo
                  rows.append(data)
          # NTIA / BSI
          for std in ["NTIA", "BSI"]:
              for path in glob.glob(f"results/**/compliance_{std}.json", recursive=True):
                  repo = os.path.basename(os.path.dirname(path))
                  data = load_json_safe(path)
                  if data:
                      data["repository"] = repo
                      data["standard"] = std
                      rows.append(data)
          # ALWAYS create summary.csv
          if not rows:
              print("âš ï¸ No SBOMQS data found â€” writing empty CSV.")
              pd.DataFrame([]).to_csv("sbomqs_summary.csv", index=False)
          else:
              df = pd.json_normalize(rows)
              df.to_csv("sbomqs_summary.csv", index=False)
              print(f"ðŸ“Š Wrote sbomqs_summary.csv with {len(rows)} rows")
          PY

      - name: Upload aggregated summary
        uses: actions/upload-artifact@v4
        with:
          name: sbomqs-summary
          path: sbomqs_summary.csv
          if-no-files-found: ignore
