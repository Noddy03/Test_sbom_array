name: üêô High-Quality Multi-Repository SBOM Harvester (Corrected)

on:
  workflow_dispatch:
    inputs:
      target_repos:
        description: 'Comma-separated list of TARGET GitHub repos (e.g., org/repo1, org/repo2)'
        required: true
        default: 'actions/checkout, actions/setup-python' 
      language:
        description: 'Language filter for deep scan (e.g., C++, Python). Use "none" for generic scan.'
        required: true
        default: 'C++'

jobs:
  # ----------------------------------------------------
  # JOB 0: SETUP MATRIX (Fixes the 'replace' error)
  # ----------------------------------------------------
  setup_matrix:
    runs-on: ubuntu-latest
    outputs:
      repo_list: ${{ steps.prepare.outputs.repo_list }}
    steps:
      - name: üìù Prepare Repository List JSON
        id: prepare
        run: |
          # Use shell scripting to safely convert the comma-separated string into a JSON array string.
          REPO_STRING="${{ github.event.inputs.target_repos }}"
          
          # 1. Remove whitespace
          CLEAN_STRING=$(echo "$REPO_STRING" | tr -d '[:space:]')
          
          # 2. Convert to JSON array format: "repo1,repo2" -> ["repo1","repo2"]
          JSON_ARRAY=$(echo "$CLEAN_STRING" | sed 's/,/","/g' | sed 's/^/["/' | sed 's/$/"]/')
          
          echo "Repository list prepared: $JSON_ARRAY"
          echo "repo_list=$JSON_ARRAY" >> $GITHUB_OUTPUT

  # ----------------------------------------------------
  # JOB 1: HARVEST AND SCAN REPOSITORIES (Parallel Matrix)
  # ----------------------------------------------------
  harvest_repos:
    runs-on: ubuntu-latest
    # DEPENDS on setup_matrix and uses its output to define the matrix
    needs: setup_matrix
    strategy:
      fail-fast: false 
      matrix:
        # Now safely consume the JSON array output from the previous job
        repository: ${{ fromJson(needs.setup_matrix.outputs.repo_list) }}
    
    steps:
      - name: ‚¨áÔ∏è Checkout Target Repository (${{ matrix.repository }})
        uses: actions/checkout@v4
        with:
          repository: ${{ matrix.repository }}
          token: ${{ secrets.GITHUB_TOKEN }} 
          path: repo-source

      - name: üêç Setup Python for Deep Scans & Merge Script
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: ‚öôÔ∏è Install Tools (CDXGen, Merge Dependencies)
        run: |
          npm install -g @cyclonedx/cdxgen
          pip install jsonpath-ng

      # ----------------------------------------------------
      # 1. ENRICHMENT SCANNER (Syft)
      # ----------------------------------------------------
      - name: üì¶ Generate SBOM with Syft (Enrichment)
        uses: anchore/syft-action/source@v0.19.0
        with:
          directory: ./repo-source
          output: "cyclonedx-json"
          file: "syft-sbom.json"

      # ----------------------------------------------------
      # 2. PRIMARY SBOM MAKERS (CDXGen Primary, Conan Optional)
      # ----------------------------------------------------
      - name: ‚öôÔ∏è Conditional Deep Scan (CDXGen Primary)
        id: cdxgen_scan
        if: |
          github.event.inputs.language != '' && 
          github.event.inputs.language != 'none' && 
          !startsWith(github.event.inputs.language, 'C') &&
          !startsWith(github.event.inputs.language, 'c')
        run: |
          LANG_INPUT="${{ github.event.inputs.language }}"
          LANG=$(echo "$LANG_INPUT" | tr '[:upper:]' '[:lower:]')
          OUTPUT_FILE="cdxgen-${LANG}-sbom.json"
          cdxgen -o "$OUTPUT_FILE" --type "$LANG" ./repo-source
          echo "CDXGEN_OUTPUT_FILE=$OUTPUT_FILE" >> $GITHUB_ENV
          echo "sbom_file_exists=true" >> $GITHUB_OUTPUT
        continue-on-error: true

      - name: ‚öôÔ∏è Conditional C/C++ Deep Scan (Conan Optional)
        id: conan_scan
        if: |
          startsWith(github.event.inputs.language, 'C') ||
          startsWith(github.event.inputs.language, 'c')
        run: |
          CONAN_FILE="conan-sbom.json"
          pip install conan 
          cdxgen -o "$CONAN_FILE" --type cpp ./repo-source
          echo "CONAN_OUTPUT_FILE=$CONAN_FILE" >> $GITHUB_ENV
          echo "sbom_file_exists=true" >> $GITHUB_OUTPUT
        continue-on-error: true

      # ----------------------------------------------------
      # 3. DATA MERGING (Creates the Final Enriched Artifact)
      # ----------------------------------------------------
      - name: üìù Run SBOM Merge Script (Supplier Enrichment & Merge)
        id: merge_and_enrich
        env:
          REPO_NAME: ${{ matrix.repository }}
          CDXGEN_FILE: ${{ steps.cdxgen_scan.outputs.sbom_file_exists && env.CDXGEN_OUTPUT_FILE || '' }}
          CONAN_FILE: ${{ steps.conan_scan.outputs.sbom_file_exists && env.CONAN_OUTPUT_FILE || '' }}
        run: |
          cat << 'EOF' > merged_and_enrich.py
import json
import re
import os
from datetime import datetime

def normalize_component(component, default_supplier):
    # CRITICAL: Ensures NTIA compliance by setting a Supplier if missing
    purl = component.get("purl", "")
    supplier_name = ""
    existing_supplier = component.get("supplier", {}).get("name", "")
    
    if not existing_supplier and purl:
        purl_match = re.match(r"pkg:(\w+)/([\w\-\.]+)/?([^@\?#]*)", purl)
        if purl_match:
            pkg_type = purl_match.group(1)
            namespace = purl_match.group(2)
            
            supplier_map = {
                "maven": "Maven Central Repository",
                "pypi": "Python Software Foundation",
                "npm": "npm, Inc.",
            }
            supplier_name = supplier_map.get(pkg_type, namespace)
            
    if supplier_name:
        component["supplier"] = {"name": supplier_name}
    elif not component.get("supplier"):
        component["supplier"] = {"name": default_supplier}
        
    return component

def merge_and_enrich(files, default_supplier):
    sboms = []
    for f in files:
        if os.path.exists(f):
            with open(f, 'r') as fp:
                try:
                    sboms.append(json.load(fp))
                except:
                    print(f"Warning: Failed to load {f}")
    
    if not sboms: return None
    merged_sbom = sboms[0]
    
    merged_sbom['metadata']['timestamp'] = datetime.now().isoformat() + 'Z'
    merged_sbom['metadata']['component']['supplier'] = {"name": default_supplier}
    
    component_map = {}
    for sbom in sboms:
        if 'components' in sbom:
            for c in sbom['components']:
                ref = c.get("purl", c.get("name") + c.get("version", ""))
                if ref and ref not in component_map:
                    component_map[ref] = c

    final_components = [normalize_component(c, default_supplier) for c in component_map.values()]
    merged_sbom['components'] = final_components
    
    return merged_sbom

if __name__ == "__main__":
    SBOM_FILES = ["syft-sbom.json"]
    if os.environ.get("CDXGEN_FILE"): SBOM_FILES.append(os.environ["CDXGEN_FILE"])
    if os.environ.get("CONAN_FILE"): SBOM_FILES.append(os.environ["CONAN_FILE"])
        
    merged_data = merge_and_enrich(SBOM_FILES, os.environ.get("REPO_NAME"))

    if merged_data:
        with open('merged-sbom.json', 'w') as f:
            json.dump(merged_data, f, indent=2)
        print("‚úÖ Successfully generated merged-sbom.json")
    else:
        exit(1)
        
EOF
        python merged_and_enrich.py

      # ----------------------------------------------------
      # 4. PRIMARY ANALYSER (Trivy)
      # ----------------------------------------------------
      - name: ü™± Scan for Vulnerabilities in Merged SBOM (Trivy Analysis)
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'sbom'
          input: 'merged-sbom.json'
          format: 'json'
          output: 'vulnerabilities.json'
          continue-on-error: true
        id: trivy_final_scan
      
      # --- Create Structured Summary for Aggregation ---
      - name: üìù Create Repo Summary JSON
        id: create_summary
        run: |
          VULN_TOTAL=$(jq '[.Results[] | .Vulnerabilities | length] | add' vulnerabilities.json 2>/dev/null || echo 0)
          VULN_CRITICAL=$(jq '[.Results[] | .Vulnerabilities[] | select(.Severity == "CRITICAL") ] | length' vulnerabilities.json 2>/dev/null || echo 0)
          
          if [ -f merged-sbom.json ]; then
            COMPONENT_COUNT=$(jq '.components | length' merged-sbom.json)
          else
            COMPONENT_COUNT=0
          fi
          
          echo "{" >> summary.json
          echo "  \"repo\": \"${{ matrix.repository }}\"," >> summary.json
          echo "  \"component_count\": $COMPONENT_COUNT," >> summary.json
          echo "  \"vuln_total\": $VULN_TOTAL," >> summary.json
          echo "  \"vuln_critical\": $VULN_CRITICAL" >> summary.json
          echo "}" >> summary.json

      - name: üì§ Upload Summary Artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.repository }}-summary
          path: summary.json
          retention-days: 1
          
  # ----------------------------------------------------
  # JOB 2: AGGREGATE RESULTS
  # ----------------------------------------------------
  aggregate_results:
    runs-on: ubuntu-latest
    needs: harvest_repos 
    steps:
      - name: üì• Download All Summaries
        uses: actions/download-artifact@v4
        with:
          path: artifacts
          pattern: '*-summary'
          merge-multiple: true 
          
      - name: üìä Aggregate Final Master CSV Report
        run: |
          sudo apt-get install -y jq
          echo "repo,component_count,vuln_total,vuln_critical" > master_report.csv
          find artifacts -name "summary.json" -print0 | while IFS= read -r -d $'\0' file; do
            REPO=$(jq -r '.repo' "$file")
            COUNT=$(jq -r '.component_count' "$file")
            TOTAL=$(jq -r '.vuln_total' "$file")
            CRIT=$(jq -r '.vuln_critical' "$file")
            echo "$REPO,$COUNT,$TOTAL,$CRIT" >> master_report.csv
          done
          
      - name: üì§ Upload Final Master Report
        uses: actions/upload-artifact@v4
        with:
          name: multi-repo-master-report
          path: master_report.csv
