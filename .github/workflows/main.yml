name: Fetch Top IoT Repositories + Trivy/Conan SBOM Scan (NTIA + BSI V2)

on:
  workflow_dispatch:
    inputs:
      language:
        description: "Programming language to scan (C++, Python, Java, etc.)"
        required: true
        default: "C++"

permissions:
  contents: read
  security-events: write
  actions: read

jobs:
  fetch_top_repos:
    runs-on: ubuntu-latest
    outputs:
      repo_list: ${{ steps.fetch.outputs.repo_list }}

    steps:
      - name: Install jq
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq

      - name: Fetch repositories
        id: fetch
        env:
          LANG: ${{ github.event.inputs.language }}
          GH_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail
          RAW_Q="topic:IoT language:$LANG fork:false archived:false"
          echo "Query: $RAW_Q"
          REPOS=$(gh api -X GET /search/repositories \
             --raw-field q="$RAW_Q" \
             --raw-field sort=stars \
             --raw-field order=desc \
             --raw-field per_page=50 \
             --jq '.items[].full_name'
          )
          echo "$REPOS"
          JSON_ARRAY=$(printf "%s\n" "$REPOS" | jq -R -s -c 'split("\n")[:-1]')
          echo "repo_list=$JSON_ARRAY" >> $GITHUB_OUTPUT

  sbom_scan:
    needs: fetch_top_repos
    runs-on: ubuntu-latest
    continue-on-error: true

    strategy:
      fail-fast: false
      matrix:
        repo: ${{ fromJSON(needs.fetch_top_repos.outputs.repo_list) }}

    steps:
      - name: Install Conan + jq + Trivy
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq wget curl python3-pip
          pip install --upgrade pip
          pip install conan
          curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh \
            | sudo sh -s -- -b /usr/local/bin

      - name: Checkout repository
        env:
          REPO: ${{ matrix.repo }}
          TOKEN: ${{ secrets.MY_PERSONAL_TOKEN || github.token }}
        run: |
          if git clone --depth=1 "https://$TOKEN@github.com/$REPO" project-src; then
              echo "skip_repo=false" >> $GITHUB_ENV
          else
              echo "skip_repo=true" >> $GITHUB_ENV
          fi

      - name: Fetch GitHub license metadata
        if: env.skip_repo != 'true'
        env:
          REPO: ${{ matrix.repo }}
          GH_TOKEN: ${{ github.token }}
        run: |
          gh api -H "Accept: application/vnd.github+json" "/repos/$REPO/license" \
             > project-src/gh-license.json 2>/dev/null \
             || echo '{"license":{"spdx_id":"NOASSERTION"}}' > project-src/gh-license.json

      - name: Local license fallback
        if: env.skip_repo != 'true'
        run: |
          FILE=$(find project-src -maxdepth=4 -type f \
            -iregex ".*\(LICENSE\|LICENCE\|COPYING\|COPYRIGHT\|LICENSE\.md\|LICENSE\.txt\)" | head -1)
          if [ -n "$FILE" ]; then
            cp "$FILE" project-src/local-license.txt
          else
            echo "" > project-src/local-license.txt
          fi

      - name: Conan SBOM
        if: env.skip_repo != 'true'
        run: |
          cd project-src
          conan profile detect --force || true
          conan graph info . --format=json > conan-sbom.json \
            || echo '{"components":[]}' > conan-sbom.json

      - name: Trivy SBOM
        if: env.skip_repo != 'true'
        run: |
          trivy fs --scanners vuln,license --format cyclonedx \
            -o project-src/trivy-fs.json project-src \
            || echo '{"components":[]}' > project-src/trivy-fs.json

      ###########################################################################
      #  ADD MISSING METADATA (Supplier, URLs, Hashes)
      ###########################################################################
      - name: Add missing SBOM metadata (supplier, URLs, hashes)
        if: env.skip_repo != 'true'
        env:
          REPO: ${{ matrix.repo }}
        run: |
          SBOM="project-src/trivy-fs.json"
          OWNER=$(echo "$REPO" | cut -d'/' -f1)
          VCS="https://github.com/$REPO"
          DIST="https://github.com/$REPO/releases"
          echo "Computing repo-level deterministic SHA-256..."
          REPO_HASH=$(find project-src -type f -exec sha256sum {} + | sha256sum | cut -d' ' -f1)

          jq --arg supplier "$OWNER" \
             --arg vcs "$VCS" \
             --arg dist "$DIST" \
             --arg hash "$REPO_HASH" '
            .components |= map(
              .supplier = { "name": $supplier } |
              .externalReferences += [
                { "type": "vcs", "url": $vcs },
                { "type": "distribution", "url": $dist }
              ] |
              .hashes = [{
                "alg": "SHA-256",
                "content": $hash
              }]
            )
          ' "$SBOM" > tmp && mv tmp "$SBOM"

      ###########################################################################
      #  ðŸ”¥ **BSI-V2 FULL COMPLIANCE PATCH** â€” MOST BULLETPROOF FIX
      ###########################################################################
      - name: Enrich SBOM for full BSI-V2 compliance
        if: env.skip_repo != 'true'
        run: |
          SBOM="project-src/trivy-fs.json"
          NOW=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

          jq --arg ts "$NOW" '
            .metadata.timestamp = $ts |
            .metadata.component.name //= "unknown" |
            .metadata.component.version //= "0.0.0" |

            .components |= map(
              .supplier //= { "name": "unknown" } |
              .name //= "unknown" |
              .version //= "0.0.0" |
              .licenses //= [{ "license": { "id": "NOASSERTION" }}] |
              .hashes //= [{ "alg": "SHA-256", "content": "0" }] |
              .purl //= ("pkg:generic/" + (.name|tostring) + "@" + (.version|tostring)) |
              .externalReferences //= [] |
              .externalReferences += [
                { "type": "website", "url": "https://github.com/" },
                { "type": "vcs", "url": "https://github.com/" }
              ]
            )
          ' "$SBOM" > tmp && mv tmp "$SBOM"

      ###########################################################################

      - name: NTIA Compliance
        if: env.skip_repo != 'true'
        run: |
          docker run --rm -v $PWD/project-src:/sbom ghcr.io/interlynk-io/sbomqs:latest \
            compliance --ntia /sbom/trivy-fs.json \
            > project-src/compliance_NTIA.json || true

      - name: BSI v2 Compliance
        if: env.skip_repo != 'true'
        run: |
          docker run --rm -v $PWD/project-src:/sbom ghcr.io/interlynk-io/sbomqs:latest \
            compliance --bsi-v2 /sbom/trivy-fs.json \
            > project-src/compliance_BSI.json || true

      - name: Score SBOM
        if: env.skip_repo != 'true'
        run: |
          docker run --rm -v $PWD/project-src:/sbom ghcr.io/interlynk-io/sbomqs:latest \
            score /sbom/trivy-fs.json --json \
            > project-src/score.json || true

      - name: Sanitize artifact name
        id: sanitize
        run: |
          SAFE="${{ matrix.repo }}"
          SAFE="${SAFE//\//_}"
          echo "name=$SAFE" >> $GITHUB_OUTPUT

      - name: Upload SBOM reports
        uses: actions/upload-artifact@v4
        with:
          name: sbom-reports-${{ steps.sanitize.outputs.name }}
          path: project-src/*.json
          if-no-files-found: warn

  aggregate_results:
    name: Aggregate SBOMQS Results
    needs: sbom_scan
    runs-on: ubuntu-latest

    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: results/

      - name: Install Python + Pandas
        run: |
          sudo apt-get update
          sudo apt-get install -y python3-pip
          pip install pandas

      - name: Aggregate SBOMQS results to CSV
        run: |
          python3 <<'PY'
          import json, glob, pandas as pd, os
          def load_json_safe(p):
              try:
                  with open(p) as f:
                      content = f.read().strip()
                      return json.loads(content) if content else None
              except:
                  return None

          rows = []

          for path in glob.glob("results/**/score.json", recursive=True):
              repo = os.path.basename(os.path.dirname(path))
              data = load_json_safe(path)
              if data:
                  data["repository"] = repo
                  rows.append(data)

          for std in ["NTIA", "BSI"]:
              for path in glob.glob(f"results/**/compliance_{std}.json", recursive=True):
                  repo = os.path.basename(os.path.dirname(path))
                  data = load_json_safe(path)
                  if data:
                      data["repository"] = repo
                      data["standard"] = std
                      rows.append(data)

          if not rows:
              print("âš ï¸ No SBOMQS data found â€” writing empty CSV.")
              pd.DataFrame([]).to_csv("sbomqs_summary.csv", index=False)
          else:
              df = pd.json_normalize(rows)
              df.to_csv("sbomqs_summary.csv", index=False)
              print(f"ðŸ“Š Wrote sbomqs_summary.csv with {len(rows)} rows")
          PY

      - name: Upload aggregated summary
        uses: actions/upload-artifact@v4
        with:
          name: sbomqs-summary
          path: sbomqs_summary.csv
          if-no-files-found: ignore
