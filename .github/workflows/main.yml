name: Fetch Top IoT Repositories + Trivy/Conan SBOM Scan (Full NTIA + BSI V2 Compliance)

on:
  workflow_dispatch:
    inputs:
      language:
        description: "Programming language to scan (e.g. C++, Python, Java)"
        required: true
        default: "C++"

permissions:
  contents: read
  security-events: write
  actions: read

jobs:
  # ---------------------------------------------------------
  # 1. FETCH TOP IoT REPOSITORIES
  # ---------------------------------------------------------
  fetch_top_repos:
    name: Fetch top 50 IoT GitHub repositories (${{ github.event.inputs.language }})
    runs-on: ubuntu-latest
    outputs:
      repo_list: ${{ steps.fetch.outputs.repo_list }}
    steps:
      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq
      - name: Fetch top 50 IoT repositories
        id: fetch
        env:
          GH_TOKEN: ${{ github.token }}
          LANG: ${{ github.event.inputs.language }}
        run: |
          echo "Fetching top 50 IoT-related repositories written in $LANG..."
          REPOS=$(gh api /search/repositories \
            --method GET \
            -F q="IoT language:$LANG fork:false archived:false" \
            -F sort=stars -F order=desc -F per_page=50 \
            --jq '.items[].full_name')
          JSON_ARRAY=$(echo "$REPOS" | jq -R -s -c 'split("\n")[:-1]')
          echo "repo_list=$JSON_ARRAY" >> $GITHUB_OUTPUT

  # ---------------------------------------------------------
  # 2. SBOM SCAN + ENRICHMENT + COMPLIANCE
  # ---------------------------------------------------------
  sbom_scan:
    name: SBOM Scan + Enrichment + NTIA/BSI V2 Compliance
    needs: fetch_top_repos
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        repo: ${{ fromJSON(needs.fetch_top_repos.outputs.repo_list) }}
    continue-on-error: true

    steps:
      - name: Setup environments
        run: |
          sudo apt-get update && sudo apt-get install -y jq uuid-runtime python3-pip coreutils
          pip install conan

      - name: Checkout repository
        id: checkout
        continue-on-error: true
        uses: actions/checkout@v4
        with:
          repository: ${{ matrix.repo }}
          path: project-src
          fetch-depth: 0
          token: ${{ secrets.MY_PERSONAL_TOKEN || github.token }}

      - name: Conan setup
        if: steps.checkout.outcome == 'success'
        run: |
          conan profile detect --force
          echo "ðŸ“¦ Conan setup complete."

      - name: Run Trivy SBOM scan
        if: steps.checkout.outcome == 'success'
        continue-on-error: true
        uses: aquasecurity/trivy-action@0.25.0
        with:
          scan-type: fs
          scan-ref: ./project-src
          format: cyclonedx
          scanners: vuln
          output: project-src/trivy-report.json
          ignore-unfixed: true
          vuln-type: os,library
          severity: CRITICAL,HIGH,MEDIUM
          timeout: 10m

      # ---------------------------------------------------------
      # SBOM ENRICHMENT (METADATA + COMPONENTS)
      # ---------------------------------------------------------
      - name: ðŸ› ï¸ Enrich CycloneDX SBOM (Metadata, Components)
        if: steps.checkout.outcome == 'success'
        run: |
          set -euo pipefail
          FILE="project-src/trivy-report.json"
          REPO="${{ matrix.repo }}"
          REPO_URL="https://github.com/$REPO"
          RELEASE_URL="$REPO_URL/releases/latest"
          TIMESTAMP=$(date -Iseconds)

          [ -f "$FILE" ] || { echo "âŒ SBOM not found"; exit 0; }

          echo "ðŸ”§ Normalizing SBOM metadata..."
          jq --arg repo "$REPO_URL" --arg ts "$TIMESTAMP" '
            .bomFormat = "CycloneDX" |
            .specVersion = "1.5" |
            .metadata.timestamp //= $ts |
            .metadata.component |= (.name // $repo | split("/")[-1]) |
            .metadata.licenses //= [{"license": {"id": "NOASSERTION"}}] |
            .metadata.tools |= (if type=="string" then [{"name": .}] elif type=="object" then [.] elif type=="array" then . else [] end) |
            .metadata.tools += [{"vendor":"Trivy","name":"CycloneDX SBOM Generator"}] |
            .metadata.properties = (.metadata.properties // []) + [
              {"name":"sbom_generator","value":"Trivy"},
              {"name":"build_environment","value":"GitHub Actions - Linux"},
              {"name":"sbom_repo","value":$repo},
              {"name":"sbom_timestamp","value":$ts}
            ]
          ' "$FILE" > tmp.json && mv tmp.json "$FILE"

          echo "ðŸ§© Enriching components with license, hash, supplier..."
          TMP="./tmp.json"
          cp "$FILE" "$TMP"

          # Safely gather up to 100 source files
          mapfile -d '' FILES < <(find project-src -type f -maxdepth 3 -print0 | head -zn 100 || true)

          for SRC in "${FILES[@]}"; do
            HASH=$(sha256sum "$SRC" | cut -d' ' -f1)
            RELPATH="${SRC#project-src/}"

            jq --arg repo "$REPO_URL" --arg rel "$RELPATH" --arg hash "$HASH" --arg release "$RELEASE_URL" '
              .components |= map(
                ."bom-ref" //= (.name + ":" + ($hash | slice(0; 8))) |
                .version //= "UNKNOWN" |
                .supplier //= {"name": ($repo | split("/")[-2])} |
                .licenses = (.licenses // [{"license":{"id":"NOASSERTION"}}]) |
                .hashes |= (. // []) + [{"alg":"SHA-256","content":$hash}] |
                .externalReferences = (.externalReferences // []) + [
                  {"type":"vcs","url":$repo},
                  {"type":"distribution","url":$release},
                  {"type":"other","comment":"source uri","url":$rel}
                ]
              )
            ' "$TMP" > tmp2.json && mv tmp2.json "$TMP"
          done

          mv "$TMP" "$FILE"

          echo "ðŸ”— Adding global references (BOM, Signature)..."
          jq --arg bom "$REPO_URL/raw/main/project-src/trivy-report.json" '
            .metadata.externalReferences += [
              {"type":"bom","url":$bom},
              {"type":"signature","url":"https://sigstore.dev"}
            ]
          ' "$FILE" > tmp.json && mv tmp.json "$FILE"

          echo "ðŸŽ‰ SBOM enrichment complete."

      # ---------------------------------------------------------
      # OPTIONAL: SIGN SBOM
      # ---------------------------------------------------------
      - name: Sign SBOM (if Cosign key available)
        if: steps.checkout.outcome == 'success'
        env:
          COSIGN_PRIVATE_KEY: ${{ secrets.COSIGN_PRIVATE_KEY }}
          COSIGN_PASSWORD: ${{ secrets.COSIGN_PASSWORD }}
        run: |
          if [ -z "$COSIGN_PRIVATE_KEY" ]; then
            echo "âš ï¸ No Cosign key provided â€” skipping signing."
            exit 0
          fi
          echo "$COSIGN_PRIVATE_KEY" > cosign.key
          cosign sign-blob --key cosign.key project-src/trivy-report.json --output-signature project-src/trivy-report.sig
          echo "ðŸ” SBOM signed successfully."

      # ---------------------------------------------------------
      # COMPLIANCE & SCORING
      # ---------------------------------------------------------
      - name: Compliance SBOM NTIA
        if: steps.checkout.outcome == 'success'
        run: |
          docker run --rm -v $PWD/project-src:/project-src \
            ghcr.io/interlynk-io/sbomqs:latest compliance \
            --ntia /project-src/trivy-report.json > project-src/compliance_NTIA.json

      - name: Compliance SBOM BSI
        if: steps.checkout.outcome == 'success'
        run: |
          docker run --rm -v $PWD/project-src:/project-src \
            ghcr.io/interlynk-io/sbomqs:latest compliance \
            --bsi-v2 /project-src/trivy-report.json > project-src/compliance_BSI.json

      - name: Score SBOM
        if: steps.checkout.outcome == 'success'
        run: |
          docker run --rm -v $PWD/project-src:/project-src \
            ghcr.io/interlynk-io/sbomqs:latest score \
            /project-src/trivy-report.json --json > project-src/score_evaluation.json

      - name: Diagnostic:Print zero-score fields
        if: steps.checkout.outcome == 'success'
        run: |
          echo "ðŸ”Ž Checking NTIA/BSI compliance zero-score fields..."
          for FILE in project-src/compliance_NTIA.json project-src/compliance_BSI.json; do
            if [ -f "$FILE" ]; then
              jq -r 'to_entries[] | select(.value == 0) | "âŒ Missing: " + .key' "$FILE"
            fi
          done
          echo "âœ” Diagnostic complete."

      - name: Sanitize artifact name
        id: sanitize
        run: |
          SAFE_NAME="${{ matrix.repo }}"
          SAFE_NAME="${SAFE_NAME//\//_}"
          echo "name=$SAFE_NAME" >> $GITHUB_OUTPUT

      - name: Upload SBOM reports
        uses: actions/upload-artifact@v4
        with:
          name: sbom-reports-${{ steps.sanitize.outputs.name }}
          path: project-src/*.json
          if-no-files-found: warn

  # ---------------------------------------------------------
  # 3. AGGREGATE RESULTS
  # ---------------------------------------------------------
  aggregate_results:
    name: Aggregate SBOMQS Results
    needs: sbom_scan
    runs-on: ubuntu-latest
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: results/

      - name: Install Python + Pandas
        run: |
          sudo apt-get update && sudo apt-get install -y python3-pip
          pip install pandas

      - name: Aggregate SBOMQS results
        run: |
          python3 <<'EOF'
          import json, glob, pandas as pd, os

          def load_json(path):
              try:
                  with open(path) as f: return json.load(f)
              except: return None

          records = []
          for std in ["NTIA", "BSI"]:
              for path in glob.glob(f"results/**/compliance_{std}.json", recursive=True):
                  repo = os.path.basename(os.path.dirname(path))
                  data = load_json(path)
                  if data:
                      data["repository"] = repo
                      data["standard"] = std
                      records.append(data)
          for path in glob.glob("results/**/score_evaluation.json", recursive=True):
              repo = os.path.basename(os.path.dirname(path))
              data = load_json(path)
              if data:
                  data["repository"] = repo
                  records.append(data)

          if not records:
              print("âŒ No valid SBOMQS records found.")
          else:
              df = pd.json_normalize(records)
              df.to_csv("sbomqs_summary.csv", index=False)
              print(f"ðŸ“Š Aggregated {len(records)} records successfully.")
          EOF

      - name: Upload summary CSV
        uses: actions/upload-artifact@v4
        with:
          name: sbomqs-summary
          path: sbomqs_summary.csv
