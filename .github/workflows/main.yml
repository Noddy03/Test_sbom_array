name: Fetch Top IoT Repositories + Trivy/Conan SBOM Scan (NTIA + BSI V2)

on:
  workflow_dispatch:
    inputs:
      language:
        description: "Programming language to scan (C++, Python, Java, etc.)"
        required: true
        default: "C++"

permissions:
  contents: read
  security-events: write
  actions: read

jobs:
  fetch_top_repos:
    runs-on: ubuntu-latest
    outputs:
      repo_list: ${{ steps.fetch.outputs.repo_list }}

    steps:
      - name: Install jq
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq

      - name: Fetch repositories
        id: fetch
        env:
          LANG: ${{ github.event.inputs.language }}
          GH_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail
          RAW_Q="topic:IoT language:$LANG fork:false archived:false"
          REPOS=$(gh api -X GET /search/repositories \
             --raw-field q="$RAW_Q" \
             --raw-field sort=stars \
             --raw-field order=desc \
             --raw-field per_page=50 \
             --jq '.items[].full_name')
          JSON_ARRAY=$(printf "%s\n" "$REPOS" | jq -R -s -c 'split("\n")[:-1]')
          echo "repo_list=$JSON_ARRAY" >> $GITHUB_OUTPUT

  sbom_scan:
    needs: fetch_top_repos
    runs-on: ubuntu-latest
    continue-on-error: true

    strategy:
      fail-fast: false
      matrix:
        repo: ${{ fromJSON(needs.fetch_top_repos.outputs.repo_list) }}

    steps:
      - name: Install Conan + jq + Trivy
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq wget curl python3-pip
          pip install --upgrade pip
          pip install conan
          curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh \
            | sudo sh -s -- -b /usr/local/bin
          docker --version || sudo systemctl start docker || true

      - name: Checkout repository
        env:
          REPO: ${{ matrix.repo }}
          TOKEN: ${{ secrets.MY_PERSONAL_TOKEN || github.token }}
        run: |
          if git clone --depth=1 "https://$TOKEN@github.com/$REPO" project-src; then
              echo "skip_repo=false" >> $GITHUB_ENV
          else
              echo "skip_repo=true" >> $GITHUB_ENV
          fi

      - name: Fetch GitHub license metadata
        if: env.skip_repo != 'true'
        env:
          REPO: ${{ matrix.repo }}
          GH_TOKEN: ${{ github.token }}
        run: |
          gh api -H "Accept: application/vnd.github+json" "/repos/$REPO/license" \
             > project-src/gh-license.json 2>/dev/null \
             || echo '{"license":{"spdx_id":"NOASSERTION"}}' > project-src/gh-license.json

      - name: Local license fallback
        if: env.skip_repo != 'true'
        run: |
          FILE=$(find project-src -maxdepth=4 -type f \
            -iregex ".*\(LICENSE\|LICENCE\|COPYING\|COPYRIGHT\|LICENSE\.md\|LICENSE\.txt\)" | head -1)
          if [ -n "$FILE" ]; then cp "$FILE" project-src/local-license.txt
          else echo "" > project-src/local-license.txt; fi

      - name: Conan SBOM
        if: env.skip_repo != 'true'
        run: |
          cd project-src
          conan profile detect --force || true
          conan graph info . --format=json > conan-sbom.json \
            || echo '{"components":[]}' > conan-sbom.json

      - name: Trivy SBOM (CycloneDX 1.4 JSON)
        if: env.skip_repo != 'true'
        run: |
          trivy fs --scanners vuln,license \
            --format cyclonedx --cyclonedx-version 1.4 \
            -o project-src/trivy-fs.json project-src \
            || echo '{"bomFormat":"CycloneDX","specVersion":"1.4","version":1,"components":[]}' > project-src/trivy-fs.json

      - name: Normalize SBOM structure
        if: env.skip_repo != 'true'
        run: |
          SBOM="project-src/trivy-fs.json"
          jq '
            .bomFormat = (.bomFormat // "CycloneDX") |
            .specVersion = (.specVersion // "1.4") |
            .version = (.version // 1) |
            .metadata = (.metadata // {}) |
            .metadata.component = (
              if (.metadata.component | type) == "object" then .metadata.component else { "bomRef": "root" } end
            ) |
            .metadata.properties = (if (.metadata.properties | type) == "array" then .metadata.properties else [] end) |
            .metadata.tools = (if (.metadata.tools | type) == "array" then .metadata.tools else [] end) |
            .metadata.licenses = (if (.metadata.licenses | type) == "array" then .metadata.licenses else [] end) |
            .components = (if (.components | type) == "array" then .components else [] end)
          ' "$SBOM" > tmp && mv tmp "$SBOM"

      - name: Add missing SBOM metadata
        if: env.skip_repo != 'true'
        env:
          REPO: ${{ matrix.repo }}
        run: |
          SBOM="project-src/trivy-fs.json"
          OWNER=$(echo "$REPO" | cut -d'/' -f1)
          VCS="https://github.com/$REPO"
          DIST="https://github.com/$REPO/releases"
          REPO_HASH=$(find project-src -type f -exec sha256sum {} + | sha256sum | cut -d' ' -f1)
          jq --arg supplier "$OWNER" \
             --arg vcs "$VCS" \
             --arg dist "$DIST" \
             --arg hash "$REPO_HASH" '
            .metadata.supplier = { "name": $supplier } |
            .components |= map(
              .externalReferences = ((.externalReferences // []) + [
                { "type": "vcs", "url": $vcs },
                { "type": "distribution", "url": $dist }
              ]) |
              .hashes = [{ "alg": "SHA-256", "content": $hash }]
            )
          ' "$SBOM" > tmp && mv tmp "$SBOM"

      - name: Add source code digest
        if: env.skip_repo != 'true'
        run: |
          SBOM="project-src/trivy-fs.json"
          SRC_HASH=$(find project-src -type f -exec sha256sum {} + | sha256sum | cut -d' ' -f1)
          jq --arg hash "$SRC_HASH" '
            .metadata.properties += [{ "name": "cdx:digest:source", "value": $hash }]
          ' "$SBOM" > tmp && mv tmp "$SBOM"

      - name: Add build metadata
        if: env.skip_repo != 'true'
        run: |
          SBOM="project-src/trivy-fs.json"
          jq '
            .metadata.lifecycle = { "phase": "build" } |
            .metadata.tools += [
              { "vendor": "github", "name": "actions", "version": "1.0" }
            ] |
            .metadata.properties += [
              { "name": "build:host", "value": "github-actions" },
              { "name": "build:timestamp", "value": (now | todate) }
            ]
          ' "$SBOM" > tmp && mv tmp "$SBOM"

      - name: Add BOM link
        if: env.skip_repo != 'true'
        run: |
          SBOM="project-src/trivy-fs.json"
          jq '
            .bomLinks = [
              { "ref": .metadata.component.bomRef, "rel": "variant" }
            ]
          ' "$SBOM" > tmp && mv tmp "$SBOM"

      - name: Add signature
        if: env.skip_repo != 'true'
        run: |
          SBOM="project-src/trivy-fs.json"
          SIG=$(sha256sum "$SBOM" | cut -d' ' -f1)
          jq --arg sig "$SIG" '
            .signature = { "algorithm": "SHA-256", "value": $sig }
          ' "$SBOM" > tmp && mv tmp "$SBOM"

      - name: Merge GitHub + Trivy + Local license
        if: env.skip_repo != 'true'
        run: |
          SBOM="project-src/trivy-fs.json"
          GH="project-src/gh-license.json"
          LOC="project-src/local-license.txt"
          GH_SPDX=$(jq -r '.license.spdx_id // empty' "$GH")
          TRIVY_SPDX=$(jq -r '[.components[]?.licenses[]?.license?.id // empty] | unique | join(",")' "$SBOM")
          LOCAL_SPDX=$( [ -s "$LOC" ] && echo CUSTOM || echo "" )
          if [ -n "$GH_SPDX" ] && [ "$GH_SPDX" != "NOASSERTION" ]; then FINAL="$GH_SPDX"
          elif [ -n "$TRIVY_SPDX" ]; then FINAL="$TRIVY_SPDX"
          elif [ -n "$LOCAL_SPDX" ]; then FINAL="$LOCAL_SPDX"
          else FINAL="NOASSERTION"; fi
          jq --arg lic "$FINAL" '
            .metadata.licenses = [{ "license": { "id": $lic }}] |
            .components |= map(
              if ((.licenses // []) | length == 0)
              then .licenses = [{ "license": { "id": $lic }}]
              else .
              end
            )
          ' "$SBOM" > tmp && mv tmp "$SBOM"

      - name: NTIA Compliance
        if: env.skip_repo != 'true'
        run: |
          docker run --rm -v $PWD/project-src:/sbom ghcr.io/interlynk-io/sbomqs:latest \
            compliance --ntia /sbom/trivy-fs.json \
            > project-src/compliance_NTIA.json || echo '{}' > project-src/compliance_NTIA.json

      - name: BSI v2 Compliance
        if: env.skip_repo != 'true'
        run: |
          docker run --rm -v $PWD/project-src:/sbom ghcr.io/interlynk-io/sbomqs:latest \
            compliance --bsi-v2 /sbom/trivy-fs.json \
            > project-src/compliance_BSI.json || echo '{}' > project-src/compliance_BSI.json

      - name: Score SBOM
        if: env.skip_repo != 'true'
        run: |
          docker run --rm -v $PWD/project-src:/sbom ghcr.io/interlynk-io/sbomqs:latest \
            score /sbom/trivy-fs.json --json \
            > project-src/score.json || echo '{}' > project-src/score.json

      - name: Sanitize artifact name
        id: sanitize
        run: |
          SAFE="${{ matrix.repo }}"
          SAFE="${SAFE//\//_}"
          echo "name=$SAFE" >> $GITHUB_OUTPUT

      - name: Upload SBOM reports
        uses: actions/upload-artifact@v4
        with:
          name: sbom-reports-${{ steps.sanitize.outputs.name }}
          path: project-src/*.json
          if-no-files-found: warn

  aggregate_results:
    name: Aggregate SBOMQS Results
    needs: sbom_scan
    runs-on: ubuntu-latest

    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: results/

      - name: Install Python + Pandas
        run: |
          sudo apt-get update
          sudo apt-get install -y python3-pip
          pip install pandas

      - name: Aggregate SBOMQS results to CSV
        run: |
          cat << 'EOF' > agg.py
          import json, glob, pandas as pd, os

          def load_json_safe(path):
              try:
                  with open(path, "r") as f:
                      txt = f.read().strip()
                      return json.loads(txt) if txt else None
              except:
                  return None

          rows = []

          for path in glob.glob("results/**/*.json", recursive=True):
              name = os.path.basename(path)

              if name == "score.json":
                  category = "score"
              elif name == "compliance_NTIA.json":
                  category = "compliance_NTIA"
              elif name == "compliance_BSI.json":
                  category = "compliance_BSI"
              else:
                  continue

              data = load_json_safe(path)
              if not data:
                  continue

              folder = os.path.basename(os.path.dirname(path))
              repo = folder.replace("sbom-reports-", "")

              data["repository"] = repo
              data["category"] = category
              rows.append(data)

          df = pd.DataFrame(rows)
          df.to_csv("sbomqs_summary.csv", index=False)
          EOF

          python3 agg.py


      - name: Upload aggregated summary
        uses: actions/upload-artifact@v4
        with:
          name: sbomqs-summary
          path: sbomqs_summary.csv
          if-no-files-found: ignore
